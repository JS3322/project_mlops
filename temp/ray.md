요구사항,Ray,Celery,BentoML
모델 메모리 상주 및 1시간 관리,Actor 모델로 자연스럽게 구현 가능,전역 캐시/전역 dict 등 직접 관리, Celery 주기적 태스크로 청소,서버 시작 혹은 첫 요청 시 로딩은 쉬우나 만료 관리 로직 직접 구현 필요
장기 실행(1시간+),Future/Actor 호출로 비동기 쉽게 구현,장기 태스크 본연의 강점. Broker/Backend 통한 상태 추적 용이,별도 비동기 처리기 필요. 기본은 짧은 온라인 예측에 초점
로드밸런싱 및 확장성,Ray 클러스터로 자동 자원 관리,워커 수 늘리면 자연스럽게 큐 소비 분산,별도 로드밸런서 필요, Bentoml 자체는 인스턴스 확대 시 수평 확장은 가능하나 자원 최적화는 수동
추가 인프라,Ray runtime만 필요,Postgres 등 Broker/Backend 필요,별도 로드밸런서, 비동기 큐 필요 시 추가 인프라 필요
생태계 성숙도/사용 사례,최근 성장, HPC/MLOPS서 자주 사용,매우 풍부하고 안정적인 생태계,ML 서빙 관점에서 빠르게 성장 중, 문서와 예제 풍부하지만 장기 태스크나 캐싱 패턴은 비주류
모델 서빙 편의성,개발자가 Actor/Task로 직접 관리 필요,모델 관리는 개발자 구현 필요,모델 서빙 특화, 버저닝, 아티팩트 관리 쉽지만 요구사항(장기/캐시 만료) 맞추려면 추가 노력